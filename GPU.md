# GPU Node Status

**Status:** Not yet provisioned
**Design:** See "GPU Inference Infrastructure — Provisioning & Health Management Design" in Linear

## When Provisioned — Update This

| Field | Value |
|-------|-------|
| DO Droplet ID | |
| Public IP | |
| Region | |
| Size | |
| Monthly Cost | |
| Provisioned | |
| Last Healthy | |

## Services

| Service | Port | Status |
|---------|------|--------|
| llama.cpp | 8080 | — |
| chatterbox | 8081 | — |
| whisper | 8082 | — |
| qwen | 8083 | — |

## Provision History

*(none yet)*

## Incident History

*(none yet)*
